{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "441caf5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class will start at 6:05 PM\n",
    "\n",
    "In the meantime... fun fact!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db19cd",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Chat GPT and other Large Language Models (LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d70594",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 4: Regression models continuation and classification models\n",
    "### Intro to Machine Learning | Professional Certificate course \n",
    "\n",
    "Viviana Marquez,  M.Sc.<br>\n",
    "March 15, 2023\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='../img/all/di.jpeg' style='width:500px; float: left; margin: 0px 30px 15px 0px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b7cd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üöÄ Today's agenda\n",
    "\n",
    "**Part 1:**\n",
    "\n",
    "- Regression models continuation \n",
    "    - Linear regression recap\n",
    "    - Performance metrics: RMSE and R-Squared\n",
    "    - Regularized models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f31e72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üöÄ Today's agenda\n",
    "\n",
    "**Part 2:**\n",
    "- Intro to classification models\n",
    "- Performance metrics for classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfccbcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚è™ Last class recap\n",
    "\n",
    "- Data pre-processing: Data cleaning and Feature Engineering \n",
    "    - Note: Your Exploratory Data Analysis should give your data pre-processing \n",
    "\n",
    "<br>\n",
    "\n",
    "- Bias-variance trade-off: We want both low bias and low variance but when one goes down, the other one goes up. Your task is to find the optimum model complexity. \n",
    "    - High Bias: Model is inaccurate on training set (too simple)\n",
    "    - High Variance: Model is too good on training set, but inaccurate on test set (aka doesn't generalize well, too complex)\n",
    "\n",
    "<br>\n",
    "\n",
    "- Intro to Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f7445a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conda environment commands\n",
    "\n",
    "- `conda activate IntroML`\n",
    "    - Launch `jupyter notebook`\n",
    "    \n",
    "    \n",
    "### Alternative\n",
    "\n",
    "Google Colab: https://colab.research.google.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f5c083",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üöÄ Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5862a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Regression models continuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe781589",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üó∫Ô∏èüìç Guide map \n",
    "\n",
    "<center>\n",
    "    <img src='../img/class_3/reg.png' style='height:550px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea0a3a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear regression\n",
    "\n",
    "- It's the most famous regression model and perhaps the most famous one of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d5af7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 2 min review: https://www.youtube.com/watch?v=CtsRRUddV2s&ab_channel=VisuallyExplained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7636f86e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's work with HW3 data\n",
    "\n",
    "- Download data [here](https://www.kaggle.com/datasets/mirichoi0218/insurance?datasetId=13720&sortBy=voteCount&select=insurance.csv) or [here](https://raw.githubusercontent.com/vivianamarquez/Intro-to-Machine-Learning/main/data/insurance.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9b00c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f94344f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üó∫Ô∏èüìç Guide map \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_0/pipeline.png' style='height:350px;'>\n",
    "</center>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55937439",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5ba0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f4b2e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a32a44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2f3c4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3f48a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7e2385",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63260b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22153efd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbdd238",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb495d17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c74a2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0157c26",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfb729a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data pre-processing: Data cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785d168",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c9004bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üëÆ‚Äç‚ôÄÔ∏è Check-in\n",
    "\n",
    "Why do we split our data into train/val/test before doing data pre-processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e21a98",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Prevent your model from overfitting \n",
    "- Accurately evaluate your model\n",
    "- Avoid data leakage (no peeking! üëÄ By pretending we've never seen the test data we can truly know how our model will perform in unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd9dc40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c2c5d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174be127",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "910a59af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üëÆ‚Äç‚ôÄÔ∏è Check-in\n",
    "\n",
    "Why did we use One Hot Encoder instead of Ordinal Encoder for the categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc13d21",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Because the Ordinal Encoder assumes two nearby values are more similar to each other (useful for ordered categories such as \"bad\", \"average\", \"good\", \"excellent\")\n",
    "- One Hot Encoder returns a binary column for each one of the labels in the categorical column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ea7b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üëÆ‚Äç‚ôÄÔ∏è Check-in\n",
    "\n",
    "Why did we use `fit()` and `fit_transform()` only on training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77713f1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Because we want to **learn the parameters** (fit) of scaling on the train data and **scale** (transform) on the train data. \n",
    "- We use `transform()` on the test data because we use the scaling parameters learned on the train data to avoid data leakage. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9206c18c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üó∫Ô∏èüìç Guide map \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_3/pipeline_train.png' style='height:350px;'>\n",
    "</center>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88af88d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intuition behind using linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011a10a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we buy one Starbucks Grande coffee for `$2.10` we know that if we buy our friend one too, it will cost us `$4.20`. The cost depends linearly on the number of cups we purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b1349",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ total = 2.10 + 2.10 \\times (\\text{number of friends}) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c7530",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y = \\beta_0 + \\beta_1 X_1 $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab639e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning making our life easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1dd5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c409d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e5c1b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753510c9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa810759",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Coefficients  \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_3/lr_formula.png' style='height:300px; float: center; margin: 0px 0px 0px 0px'><br>\n",
    "</center>\n",
    "\n",
    "\n",
    "- A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent variable also tends to increase.\n",
    "\n",
    "- A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease.\n",
    "- Your goal with linear regression is finding those optimal coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d328d4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302bd9a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b48f751",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44940c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ü§î How do I know if my model is good? \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_4/err.webp' style='height:250px; float: center; margin: 0px 0px 0px 0px'><br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f3832a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Linear Regression tries to fit a line that produces the smallest difference between predicted and actual values. This difference error is also known as residual.\n",
    "\n",
    "$$e=y-\\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7452a40c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Performance metrics** are a measure of how good a model predicts values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f43ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some linear regression metrics:\n",
    "    - MSE: Mean Square Error\n",
    "    - MAE: Mean Absolute Error\n",
    "    - RMSE: Root Mean Square Error\n",
    "    - R-squared\n",
    "    - Adjusted R-Square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fd530",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RMSE: Root Mean Square Error\n",
    "\n",
    "$$RMSE = \\sqrt{\\dfrac{\\sum^{N}_{i=1}||y_i-\\hat{y}_i||^2}{N}}$$\n",
    "\n",
    "where $N$ is the number of data poits, $y_i$ is the i-th observation and $\\hat{y}_i$ is the corresponding prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656117a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It shows how far predictions fall from measured true values using Euclidean distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a6bfc5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee87244",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3d5b367",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ü§î What does this number mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dfd99a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A large RMSE generally means our model is failing to account for important features underlying our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ef7c6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- You want a small RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bcaf3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ü§î What does it mean for RMSE to be small?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a412752d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It depends on our choice of units and the specific application we are hoping for. (Example: 100 nanometers vs 100 kilometers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b772350",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "‚ö†Ô∏è - RMSE penalizes large errors (i.e. sensitive to outliers)\n",
    "‚ö†Ô∏è - RMSE increases with an increase in the size of the test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064eedc1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# R-Squared\n",
    "\n",
    "$$R^2 = 1 - \\dfrac{\\text{Sum of Square Error}}{\\text{Sum of Square Total}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fdc477",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How much of the variance of the outcome is explained by the model attributes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0519610",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2136768",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- R-Squared goes from 0 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34823f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Interpretation: Our attributes explain 78% of the variance in insurance price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd0bdf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We want this number to be as close to 1 as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bead9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ü§î RMSE vs. R2: Which Metric Should You Use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af3b86",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's useful to calculate both the $RMSE$ and the $R^2$ value because each metric tells us something different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a86b90",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $RMSE$: the typical distance between the predicted value made by the regression model and the actual value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b9e68",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $R^2$: how well the predictor variables can explain the variation in the response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d2074",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ü§î How can I get a better result?\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_0/pipeline.png' style='height:200px;'>\n",
    "</center>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a4e56",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Add more data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970cae0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Treat missing and outlier values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6022316",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190bb0ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ü§î How can I get a better result?\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_0/pipeline.png' style='height:200px;'>\n",
    "</center>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1255eccd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Feature Selection (Week 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321518e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "5. Hyperparameter tunning (Week 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e7acd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "6. Ensemble methods (Week 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd32d41",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "7. Cross Validation (Week 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d35895",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ü§î How can I get a better result?\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_0/pipeline.png' style='height:200px;'>\n",
    "</center>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22146ffd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "8. Try different models (Now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa618f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Regularized models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f24601",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f6c88f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Regularization is the process of introducing additional information to minimize overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b6f3a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Regularization discourages unnecessary complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea19c4aa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When there is insufficient data, regularization stabilizes our models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee0c17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# One way to regularize: Add a constraint to the loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e253bd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Loss function: Evaluating how well your algorithm is modeling your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f149a9ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The loss function for linear regression is\n",
    "\n",
    "$$SSE = \\sum^{n}_{i=1} (y_i - \\hat{y}_i)2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa425d2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Regularized loss = Loss function + Constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a9a54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lasso regression a.k.a. L1 regularization\n",
    "\n",
    "$$SSE = \\sum^{n}_{i=1} (y_i - \\hat{y}_i)2 + L1$$\n",
    "\n",
    "$$L1: \\lambda \\sum^{m}_{j=1}|w_j|$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9874a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Shrink the weights using the absolute values of the weight coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12158b42",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The effect: Penalize large coefficients-- large coefficients increase the size of the total error function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e9eb8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "987bd837",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Spoilers alert: L1 forces features to have zero as coefficients, therefore, lasso is used for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d6406",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aaa64b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd553d77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ridge regression a.k.a. L2 regularization\n",
    "\n",
    "$$SSE = \\sum^{n}_{i=1} (y_i - \\hat{y}_i)2 + L2$$\n",
    "\n",
    "$$L2: \\lambda \\sum^{n}_{j=1}w^2_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb47188",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Shrink the weights by computing the Euclidean norm of the weight coefficients (the weight vector )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248dddb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ee381",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c93173",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7505719",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üöÄ Part 2\n",
    "\n",
    "See you here at @"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a481656",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Intro to classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50f98e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regressor vs Classifier; 2 sides of the same coin\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_3/reg_class.png' style='height:400px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09209a5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üó∫Ô∏èüìç Guide map \n",
    "\n",
    "<center>\n",
    "    <img src='../img/class_1/classification.png' style='height:550px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c4222",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification models\n",
    "\n",
    "There are three types of classification models:\n",
    "\n",
    "- Binary\n",
    "- Multiclass\n",
    "- Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9604ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification models\n",
    "\n",
    "**Binary:** Classify two classes\n",
    "\n",
    "<center><img src='../img/class_4/classf1.png' style='height:600px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19109bea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification models\n",
    "\n",
    "**Multiclass:** Classify more than two classes\n",
    "\n",
    "<center><img src='../img/class_4/classf2.png' style='height:600px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c4935",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification models\n",
    "\n",
    "**Multilabel:** When a single observation has more than one label\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_4/catdog.png' style='height:600px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe17457",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üëÆ‚Äç‚ôÄÔ∏è Check-in\n",
    "\n",
    "What other problems are examples of multilabel classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bdd95",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Performance metrics for classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213853e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some performance metrics for classification models\n",
    "\n",
    "- Accuracy\n",
    "- Precision \n",
    "- Recall\n",
    "- F1-score \n",
    "- ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f45d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# When using a classification model for prediction, you can get two results \n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_4/right_wrong.png' style='height:300px; float: center; margin: 0px 0px 0px 0px'></center>\n",
    "\n",
    "- Correct \n",
    "- Incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d721c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accuracy\n",
    "\n",
    "- The number of correct predictions divided by the total number of predictions\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_4/acc.png' style='height:280px; float: center; margin: 0px 0px 0px 0px'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb6417",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Accuracy $\\dfrac{7}{10} = 0.7$ or 70% accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ec29b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Issues with accuracy\n",
    "\n",
    "- It needs a balanced data set \n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_4/acc2.png' style='height:280px; float: center; margin: 0px 0px 0px 0px'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e5792",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Accuracy $\\dfrac{9}{10} = 0.9$ or 90% accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e9c5c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recall\n",
    "\n",
    "- The ability of the model to retrieve **all** relevant cases within a data set \n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_4/acc.png' style='height:280px; float: center; margin: 0px 0px 0px 0px'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e9d96",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Let `dog` be true positive (TP) and `cat` be true negative (TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da553bd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Recall $= \\dfrac{\\text{TP}}{\\text{TP}+\\text{FN}} = \\dfrac{\\text{TP}}{\\text{everything that is actually positive}} = \\dfrac{2}{3} = \\text{67% recall}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74910248",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Precision\n",
    "\n",
    "- The ability of the model to find **only** the relevant cases within a data set\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_4/acc.png' style='height:280px; float: center; margin: 0px 0px 0px 0px'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b4a48",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Precision $= \\dfrac{\\text{TP}}{\\text{TP}+\\text{FP}} = \\dfrac{\\text{TP}}{\\text{everything that got classified as positive positive}} = \\dfrac{2}{4} = \\text{50% precision}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c80a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# F1\n",
    "\n",
    "- It is used to find an optimal balance between precision and recall\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_4/acc.png' style='height:280px; float: center; margin: 0px 0px 0px 0px'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e3faa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- $F_1 = 2 \\cdot \\dfrac{\\text{precision}\\cdot\\text{recall}}{\\text{precision}+\\text{recall}} = 2 \\cdot \\dfrac{(2/3)\\cdot(2/4)}{(2/3)+(2/4)} = \\dfrac{4}{7} = 57\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397b967",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# When using a classification model for prediction, you can get two results: \n",
    "\n",
    "- Correct \n",
    "- Incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad8fc8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That means that you end up with four groups (in a binary classification):\n",
    "\n",
    "- Correct classification `class 1`: True Positive (TP)\n",
    "<img src='../img/class_4/TP.png' style='height:120px; float: center; margin: 0px 15px 15px 0px'>\n",
    "- Correct classification `class 2`: True Negative (TN)\n",
    "<img src='../img/class_4/TN.png' style='height:120px; float: center; margin: 0px 15px 15px 0px'>\n",
    "- Incorrect classification `class 2`: False Positive (FP)\n",
    "<img src='../img/class_4/FP.png' style='height:120px; float: center; margin: 0px 15px 15px 0px'>\n",
    "- Incorrect classification `class 1`: False Negative (FN)\n",
    "<img src='../img/class_4/FN.png' style='height:120px; float: center; margin: 0px 15px 15px 0px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c87909c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Confusion matrix\n",
    "\n",
    "- Tool that helps visualize the performance of a classification model\n",
    "- The name stems from the fact that it makes it easy to see whether the system is confusing two classes\n",
    "\n",
    "<center><img src=\"../img/class_4/conf_matrix.png\" style='height:600px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509112a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "<center><img src=\"../img/class_4/conf_matrix2.png\" style='height:450px; float: center; margin: 0px 0px 0px 0px'></center>\n",
    "<br>\n",
    "<center><img src='../img/class_4/acc.png' style='height:200px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd97bbe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"../img/class_4/pregnant.jpeg\" style='height:500px; float: center; margin: 0px 0px 0px 0px'></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "- The main purpose of the confusion matrix is to obtain measures to compare the predicted values with the true values\n",
    "- What constitutes a \"good\" measure depends on the situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c288bce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# More classification performance metrics\n",
    "\n",
    "- Terminology and derivations from a confusion matrix: [here](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "- ROC (Receiver Operator Characteristic) graphs and AUC (the area under the curve): [here](https://www.youtube.com/watch?v=4jRBRDbJemM&ab_channel=StatQuestwithJoshStarmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0d4f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚è™ Today's recap\n",
    "\n",
    "- Regression models continuation \n",
    "    - Linear regression recap\n",
    "    - Performance metrics: RMSE and R-Squared\n",
    "    - Regularized models\n",
    "    \n",
    "- Intro to classification models\n",
    "- Performance metrics for classification models\n",
    "    - TP/TN/FP/FN\n",
    "    - Accuracy (careful of unbalanced datasets!)\n",
    "    - Precision and Recall\n",
    "    - F1: Optimal balance between precision and recall\n",
    "    - Confusion matrix: Tool to obtain measures to compare the predicted values with the true values\n",
    "    - ROC/AUC [this video is highly encouraged](https://www.youtube.com/watch?v=4jRBRDbJemM&ab_channel=StatQuestwithJoshStarmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a7a07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üëÆ‚Äç‚ôÄÔ∏è Misc:\n",
    "\n",
    "- Self-graded quiz will be posted in the next hour\n",
    "- üí™ Ungraded homework will be posted tonight or tomorrow morning\n",
    "- Office hours on Friday at 12 PM PST and Monday 6 PM PST (Zoom link is posted in Canvas) \n",
    "- ü§ù Networking: https://usfca.instructure.com/courses/1613920/discussion_topics/8157912?module_item_id=17968302 \n",
    "\n",
    "### Check-in: https://forms.gle/iPGEKNwJP1c8ftSp8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2900de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src='../img/all/bye.gif' style='height:400px;'> \n",
    "</center>\n",
    "\n",
    "# Next class: \n",
    "- Classification models continuation\n",
    "- Non-parametric models\n",
    "- Ensemble models"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
