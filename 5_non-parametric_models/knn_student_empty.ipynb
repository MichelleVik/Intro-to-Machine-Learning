{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "544ad31f",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- `pip install mlxtend`\n",
    "- `pip install cmasher`\n",
    "- `pip install graphviz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae2109d",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441caf5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class will start at 6:05 PM\n",
    "\n",
    "In the meantime... fun fact!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db19cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Sales and marketing is the most profitable area for machine learning. (McKinsey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceefe4f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Nissan has increased its conversion rate by 67% with a machine learning model. (Think with Google)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c751a9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Recommendations account for 80% of the movies watched on Netflix. (Cult of Mac, ResearchGate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c9079f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A machine learning algorithm can detect epilepsy in children with 73% accuracy (similar to human doctors on adults) (ScienceDirect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f79e0cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Machine learning statistics show 95% accuracy in reading lips. (outperformed experienced human lip readers) (McKinsey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a2fe36",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The employment of computer and research scientists is expected to grow by 22% from 2020 to 2030. (avg for all occupations is 4%) (BLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fa2e31",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The employment of computer and research scientists is expected to grow by 22% from 2020 to 2030. (avg for all occupations is 4%) (BLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaaf25",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 40% of newly filed patent applications in the healthcare sector have an AI or machine learning aspect. (Kluwer Patent Blog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d70594",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 5: Classification models continuation and non-parametric models\n",
    "### Intro to Machine Learning | Professional Certificate course \n",
    "\n",
    "Viviana Marquez,  M.Sc.<br>\n",
    "March 22, 2023\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='../img/all/di.jpeg' style='width:500px; float: left; margin: 0px 30px 15px 0px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b7cd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üöÄ Today's agenda\n",
    "\n",
    "**Part 1:**\n",
    "\n",
    "- Classification models continuation \n",
    "    - Logistic regression\n",
    "    - Support Vector Machines (SVM)\n",
    "    - Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f31e72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üöÄ Today's agenda\n",
    "\n",
    "**Part 2:**\n",
    "\n",
    "- Non-parametric models\n",
    "    - KNN\n",
    "    - Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfccbcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚è™ Last class recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44f8bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Regression models continuation \n",
    "    - Linear regression recap\n",
    "    - Performance metrics: RMSE and R-Squared\n",
    "    - Regularized models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c8f93",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intro to classification models\n",
    "    - Binary\n",
    "    - Multiclass\n",
    "    - Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e6d8d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Performance metrics for classification models\n",
    "    - TP/TN/FP/FN\n",
    "    - Accuracy (careful of unbalanced datasets!)\n",
    "    - Precision: The ability of the model to find **only** the relevant cases within a data set (TP/classified as positive)\n",
    "    - Recall: The ability of the model to retrieve **all** relevant cases within a data set (TP/actually positive)\n",
    "    - F1: Optimal balance between precision and recall\n",
    "    - Confusion matrix: Tool to obtain measures to compare the predicted values with the true values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f7445a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conda environment commands\n",
    "\n",
    "- `conda activate IntroML`\n",
    "    - Launch `jupyter notebook`\n",
    "    \n",
    "    \n",
    "### Alternative\n",
    "\n",
    "Google Colab: https://colab.research.google.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f5c083",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üöÄ Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a481656",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50f98e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Is it a cat or a dog?\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_5/catdog2.jpeg' style='height:400px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d81f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# It's a cat!\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_5/catdog.jpg' style='height:400px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09209a5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üó∫Ô∏èüìç Guide map \n",
    "\n",
    "<center>\n",
    "    <img src='../img/class_1/classification.png' style='height:550px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942eaf53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regressor vs Classifier; 2 sides of the same coin\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_3/reg_class.png' style='height:400px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10731a08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification models\n",
    "\n",
    "Three different flavors: \n",
    "- Binary classification \n",
    "- Multiclass classification (classify more than two classes)\n",
    "- Multilabel classification (a single observation can have more than one label)\n",
    "<br>\n",
    "<center><img src='../img/class_5/clas2.png' style='height:400px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3556f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some performance metrics for classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baef41c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Accuracy** $= \\dfrac{\\text{TP+TN}}{\\text{TP}+\\text{TN}+\\text{FP}+\\text{FN}} = \\dfrac{\\text{correctly classified}}{\\text{number of observations}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2e14e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Recall** $= \\dfrac{\\text{TP}}{\\text{TP}+\\text{FN}} = \\dfrac{\\text{TP}}{\\text{what it's actually positive}} $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94eb60",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Precision** $= \\dfrac{\\text{TP}}{\\text{TP}+\\text{FP}} = \\dfrac{\\text{TP}}{\\text{what got classified as positive}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7033845",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **F1** $= 2 \\cdot \\dfrac{\\text{precision}\\cdot\\text{recall}}{\\text{precision}+\\text{recall}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809acf3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"../img/class_5/conf_matrix.png\" style='height:800px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5862a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885f6d0d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<center><img src='../img/class_5/rm.png' style='height:500px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f700d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<center><img src='../img/class_5/rm2.png' style='height:500px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb2513",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c3c35",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's the most famous Machine Learning model after Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f789b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- While you use linear regression to predict **continuous** values, logistic regression is <u>typically</u> used to classify **discrete** values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd916bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Predictions are mapped between 0 and 1, which means that they can be interpreted as probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcefa77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54e2c0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### üëç Pros \n",
    "\n",
    "- The predictions have an elegant probabilistic representation \n",
    "- The model can be regularized to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5c280",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### üëé Cons \n",
    "\n",
    "- Tends to underperform when there are multiple decision lines or these are non-linear \n",
    "- Not flexible enough to capture more complex relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8dab66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b489928",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Support Vector Machines (SVM)\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src='../img/class_5/svm1.png' style='height:400px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee5c37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SVM\n",
    "\n",
    "How would you separate this 1-dimensional data into two classes?\n",
    "<br>\n",
    "\n",
    "<center><img src='../img/class_5/svm2.png' style='height:400px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce8055d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db651f8e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SVM\n",
    "\n",
    "How would you separate this 2-dimensional data into two classes?\n",
    "<br>\n",
    "\n",
    "<center><img src='../img/class_5/svm3.png' style='height:400px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4090b4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd5247",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How decision boundaries scale with dimensionality?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a9cef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A point in 1 dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bed167",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A line (or curve) in 2 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1a86f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A plane in 3 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b130a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A _______ in higher dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91d390",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "    - Answer: Hyperplane (or manifold)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097b20c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learn a decision bound\n",
    "\n",
    "<center><img src='../img/class_5/svm8.png' style='height:400px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5410a40a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Find a boundary that divides the classes from each other (training)\n",
    "- Use that boundary to predict class membership for new data (inference)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cb7d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which line represents the best separation?\n",
    "<br>\n",
    "<center><img src='../img/class_5/svm4.png' style='height:400px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9993fc5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Margin\n",
    "<br>\n",
    "<center><img src='../img/class_5/svm4b.png' style='height:400px; float: center; margin: 0px 0px 0px 0px'></center>\n",
    "\n",
    "- Rather than drawing a zero-width lune between the classes, draw a margin around each one of some width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61887e1c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Maximize the margin\n",
    "<br>\n",
    "<center><img src='../img/class_5/svm5.png' style='height:400px; float: center; margin: 0px 0px 0px 0px'></center>\n",
    "\n",
    "- The margin is up to the nearest point of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb66bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Maximize the margin\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_5/svm9.gif' style='height:400px; float: center; margin: 0px 0px 0px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- SVMs use a mechanism called kernel that essentially calculates the distance between two observations. With this, the model finds an optimal decision boundary (hyperplane) to separate the classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34953246",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SVM\n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_5/svm7.png' style='height:400px;'></center>\n",
    "<br>\n",
    "\n",
    "- An SVM with a linear kernel is very similar to logistic regression, so it is generally used with nonlinear kernels with nonlinear data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b30640",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c1a16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### üëç Pros \n",
    "\n",
    "- It can model non-linear relationships\n",
    "- There are many kernels to choose from\n",
    "- Good at avoiding overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b876c8ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### üëé  Cons \n",
    "\n",
    "- Intense with memory usage\n",
    "- Difficult to finetune, difficult to choose kernel\n",
    "- It doesn't do well with large data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2c9bd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f9e708",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Naive-Bayes for classification \n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src='../img/class_5/nb.jpg' style='height:400px; float: center; margin: 0px 0px 0px 0px'></center>\n",
    "<br>\n",
    "\n",
    "- Model based on Bayes' theorem which explains conditional probability. The model is updated through your training data\n",
    "- It is called \"naive\" because it assumes conditional independence (all attributes are independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f70ea85",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f61fe5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### üëç Pros \n",
    "\n",
    "- Although the conditional independence assumption is rarely true, it has surprisingly good results in practice\n",
    "- The model is easy to implement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69961297",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### üëé  Cons \n",
    "\n",
    "- Due to its simplicity, although it has good results, other models generally have better results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89139096",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Coding time! \n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_5/excited.gif' style='height:200px; float: center; margin: 0px 0px 0px 0px'></center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766af30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üó∫Ô∏èüìç Guide map \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_0/pipeline.png' style='height:550px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd21d82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1. Let's get labeled data\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_5/iris.png' style='height:550px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b8c9c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f4c5b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77fe952",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd62115",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17e63b59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2. EDA (homework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53fa39",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004976ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173be617",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7736f9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119f635",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db621e85",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c317e269",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3. Data pre-processing: Data cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a59af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üëÆ‚Äç‚ôÄÔ∏è Check-in\n",
    "\n",
    "What's the first thing you have to do before starting with data pre-processing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec18f9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Splitting dataset into training and test!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107e272",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3. Data pre-processing: Data cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2d8d4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69feaaf9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ea53e9e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the interest of time, I'll skip FE for this example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de8f6d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4. Train the model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f997c785",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c06b9c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3cd4d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31e9546b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 5. Fine-tune your model \n",
    "\n",
    "We'll skip this step for now. This is why we don't have a validation dataset for this exercise. We'll revisit this again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766c5f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 6. Get performance metrics (and re-train if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2515736",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18c031",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510416f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39fb903c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942e59e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a163133b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47bb589",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e511a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc985eac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "740fa7ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- So far, everything we've coded for all the models is exactly the same \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb678ba3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now let's look at some of the characteristics of each model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec759f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d415f28",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `predict()`: predict the actual label of an observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18abafd3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5054418e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `predict_proba()`: returns the class probabilities for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b660e8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "297a25e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SVM\n",
    "\n",
    "- As you might've noticed, Logistic Regression and SVM led to identical predictions. This because SVM was using the default kernel\n",
    "- You can change the kernel [learn more here](https://www.kdnuggets.com/2016/06/select-support-vector-machine-kernels.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33c24a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312c4ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53899d4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cc54b53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plotting SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbdad48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce49b6a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153fed57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a64b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544033ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701088d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae4d85",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc97704",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7505719",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üöÄ Part 2\n",
    "\n",
    "See you here at @"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39c2b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Non-parametric models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ae44c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So far we have only learned about parametric machine learning models..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88af88d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intuition behind using linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011a10a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we buy one Starbucks Grande coffee for `$2.10` we know that if we buy our friend one too, it will cost us `$4.20`. The cost depends linearly on the number of cups we purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b1349",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ total = 2.10 + 2.10 \\times (\\text{number of friends}) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c7530",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y = \\beta_0 + \\beta_1 X_1 $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873d788b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A **parametric** machine learning algorithm assumes a specific mathematical form of the data distribution, and estimates the parameters of this distribution based on data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc48ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Parametric** machine learning models:\n",
    "    - Fixed number of parameters\n",
    "    - It doesn't depend on the number of rows present in your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374a771",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A **non-parametric** machine learning algorithm DOES NOT assume a specific mathematical form and instead attempts top learn the pattern directly from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542bb14",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Non-parametric** machine learning models:\n",
    "    - Model structure is determined from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098cff95",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7792f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# k-Nearest Neighbors (KNN)\n",
    "\n",
    "- Let's imagine you're creating a model to predict rent prices in San Francisco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80d543",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ü§î How would people do it manually?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a590d5e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Find a few comparable apts and then predict average price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e397011",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- That's KNN! üí•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73616ae2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# k-Nearest Neighbors (KNN)\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_5/knn_method.webp' style='height:550px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1f91e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# k-Nearest Neighbors (KNN)\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_5/knn7.webp' style='height:550px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36d2cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# k-Nearest Neighbors (KNN) steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce1ed46",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 1. Have labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e2d05",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 2. Pick $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5b01d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 3. Get new sample to classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b81fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 4. Compute all the distances between the new sample and all the observations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58d2f4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 5. Select the $k$ entires that are closest to the new sample "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f15f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 6. Take a simple majority vote to pick category from new sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7f0ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de52754",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### üëç Pros \n",
    "\n",
    "- Simple - easy to apply and interpret\n",
    "- No assumptions about distribution of data  - useful for ill-tempered data\n",
    "- No training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03244ec9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### üëé Cons\n",
    "\n",
    "- High memory requirement - stores all of the data\n",
    "- Computationally expensive  - must compute all distances\n",
    "- Sensitive to irrelevant features and the feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e7d0f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üëÆ‚Äç‚ôÄÔ∏è Check-in\n",
    "\n",
    "What type of model is KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ddee2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Supervised, classification, nonparametric model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe33c25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üó∫Ô∏èüìç Guide map \n",
    "\n",
    "<center>\n",
    "    <img src='../img/class_1/classification.png' style='height:550px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b019564",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üëÆ‚Äç‚ôÄÔ∏è Check-in\n",
    "\n",
    "What's the lowest and the highest value of $k$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07247b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Lowest: $k=1$\n",
    "- Highest: $k=n$ ($n$ being the number of observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0829a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üëÆ‚Äç‚ôÄÔ∏è Check-in\n",
    "\n",
    "What happens when $k$ = $n$? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dc643",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The majority class is **always** chosen\n",
    "- Underfitting (high bias, low variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2415f23",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "How to pick $k$?\n",
    "\n",
    "Derive a plot between the error rate and different $k$s. Then choose the $k$ value with the lowest error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d7450",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e944a0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decision trees\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src='../img/class_5/dt.gif' style='height:350px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907821b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is an algorithm that can be used for both classification and regression\n",
    "- The goal is to create a model that predicts the value of the target variable by learning simple decision rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f74c55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decision trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af1eaa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### üëç Pros \n",
    "\n",
    "- The predictions have an elegant probabilistic representation \n",
    "- The model can be regularized to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d9547d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### üëé Cons\n",
    "\n",
    "- Prone to overfitting\n",
    "- Unstable, but that can be solved with an ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51fb87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1324895",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src='../img/class_5/spoiler.jpg' style='height:350px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296e13e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src='../img/class_5/rf.png' style='height:350px; float: center; margin: 0px 0px 0px 0px'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a272dd25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚ùáÔ∏è Coding time! \n",
    "\n",
    "<br>\n",
    "<center><img src='../img/class_5/excited.gif' style='height:200px; float: center; margin: 0px 0px 0px 0px'></center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858fe00",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf02b1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37d4bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2af4203",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plotting Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26bef7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c928d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edb02021",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parametric vs non-parametric\n",
    "|                    **Parametric**                   |             **Non-parametric**             |\n",
    "|:---------------------------------------------------:|:------------------------------------------:|\n",
    "| Makes assumption about form of the function of data |                No assumption               |\n",
    "|                   Simple function                   |                   Complex                  |\n",
    "|                        Faster                       |   Slower & computationally more expensive  |\n",
    "|                    Need less data                   |               Need more data               |\n",
    "|                       Underfit                      |                   Overfit                  |\n",
    "|  Model stays the same when number of rows increase  | Model changes when number of rows increase |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0d4f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚è™ Today's recap\n",
    "\n",
    "- Classification models continuation \n",
    "    - Logistic regression\n",
    "    - Support Vector Machines (SVM)\n",
    "    - Naive-Bayes\n",
    "    \n",
    "- Non-parametric models\n",
    "    - KNN\n",
    "    - Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a7a07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üëÆ‚Äç‚ôÄÔ∏è Misc:\n",
    "\n",
    "- Self-graded quiz will be posted in the next hour\n",
    "- üí™ Ungraded homework will be posted tonight or tomorrow morning\n",
    "- Office hours on Friday at 12 PM PST and Monday 6 PM PST (Zoom link is posted in Canvas) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2900de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src='../img/all/bye.gif' style='height:400px;'> \n",
    "</center>\n",
    "\n",
    "# Next class: \n",
    "- Ensemble models\n",
    "- Model optimization\n",
    "- Model interpretation"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
